{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node:\n",
    "    \n",
    "    def __init__(self, index, t, true_branch, false_branch):\n",
    "        self.index = index\n",
    "        self.t = t\n",
    "        self.true_branch = true_branch\n",
    "        self.false_branch = false_branch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Leaf:\n",
    "    \n",
    "    def __init__(self, data, labels):\n",
    "        self.data = data\n",
    "        self.labels = labels\n",
    "        self.prediction = self.predict()\n",
    "        \n",
    "    def predict(self):\n",
    "        prediction = np.mean(self.labels)\n",
    "        return prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyTreeRegressor:\n",
    "    \n",
    "    def __init__(self, max_depth=3, min_leaf = 5, max_values = 150):\n",
    "        self.max_depth = max_depth\n",
    "        self.min_leaf = min_leaf\n",
    "        self.max_values = max_values\n",
    "        self.tree = None\n",
    "        \n",
    "    def dispersion(self, labels):\n",
    "        return np.std(labels)\n",
    "\n",
    "    def quality(self, left_labels, right_labels, current_dispersion):\n",
    "        p = float(left_labels.shape[0]) / (left_labels.shape[0] + right_labels.shape[0])\n",
    "        return current_dispersion - p * self.dispersion(left_labels) - (1 - p) * self.dispersion(right_labels)\n",
    "\n",
    "    def split(self, data, labels, index, t):\n",
    "        left = np.where(data[:, index] <= t)\n",
    "        right = np.where(data[:, index] > t)\n",
    "        \n",
    "        true_data = data[left]\n",
    "        false_data = data[right]\n",
    "        true_labels = labels[left]\n",
    "        false_labels = labels[right]\n",
    "        \n",
    "        return true_data, false_data, true_labels, false_labels\n",
    "\n",
    "    def find_best_split(self, data, labels):\n",
    "        \n",
    "        current_dispersion = self.dispersion(labels)\n",
    "\n",
    "        best_quality = 0\n",
    "        best_t = None\n",
    "        best_index = None\n",
    "    \n",
    "        n_features = data.shape[1]\n",
    "    \n",
    "        for index in range(n_features):\n",
    "            t_values = np.unique([row[index] for row in data])\n",
    "            \n",
    "            if t_values.shape[0] > self.max_values:\n",
    "                t_values = np.quantile([row[index] for row in data], np.linspace(0.01, 0.99, 99))\n",
    "      \n",
    "            for t in t_values:\n",
    "                true_data, false_data, true_labels, false_labels = self.split(data, labels, index, t)\n",
    "                if len(true_data) < self.min_leaf or len(false_data) < self.min_leaf:\n",
    "                    continue\n",
    "        \n",
    "                current_quality = self.quality(true_labels, false_labels, current_dispersion)\n",
    "            \n",
    "                if current_quality > best_quality:\n",
    "                    best_quality, best_t, best_index = current_quality, t, index\n",
    "\n",
    "        return best_quality, best_t, best_index\n",
    "\n",
    "    # Построение дерева с помощью рекурсивной функции\n",
    "\n",
    "    def build_tree(self, data, labels, tree_depth, max_depth):\n",
    "\n",
    "        quality, t, index = self.find_best_split(data, labels)\n",
    "        \n",
    "        if quality == 0:\n",
    "            return Leaf(data, labels)\n",
    "        \n",
    "        if tree_depth >= max_depth:\n",
    "            return Leaf(data, labels)\n",
    "        \n",
    "        tree_depth += 1\n",
    "\n",
    "        true_data, false_data, true_labels, false_labels = self.split(data, labels, index, t)\n",
    "\n",
    "        true_branch = self.build_tree(true_data, true_labels, tree_depth, max_depth)\n",
    "        false_branch = self.build_tree(false_data, false_labels, tree_depth, max_depth)\n",
    "\n",
    "        return Node(index, t, true_branch, false_branch)\n",
    "\n",
    "    def predict_object(self, obj, node):\n",
    "        \n",
    "        if isinstance(node, Leaf):\n",
    "            answer = node.prediction\n",
    "            return answer\n",
    "\n",
    "        if obj[node.index] <= node.t:\n",
    "            return self.predict_object(obj, node.true_branch)\n",
    "        else:\n",
    "            return self.predict_object(obj, node.false_branch)\n",
    "\n",
    "    def predict(self, data):\n",
    "    \n",
    "        val = []\n",
    "        for obj in data:\n",
    "            prediction = self.predict_object(obj, self.tree)\n",
    "            val.append(prediction)\n",
    "        return val\n",
    "\n",
    "    def fit(self, data, labels):\n",
    "        self.tree = self.build_tree(data, labels, 0, self.max_depth)\n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyGradienBoost:\n",
    "    \n",
    "    def __init__(self, max_depth = 3, alpha = 0.1, l2 = True, \n",
    "                 max_trees = 100, lr_decrement = 0.5, min_leaf = 5, max_values = 150):\n",
    "        self.max_depth = max_depth\n",
    "        self.min_leaf = min_leaf\n",
    "        self.max_values = max_values\n",
    "        self.alpha = alpha\n",
    "        self.trees = []\n",
    "        self.coefs = []\n",
    "        #self.coefs = [1] * self.n_trees\n",
    "        self.loss = self.bias_l2 if l2 else self.bias_l1\n",
    "        self.max_trees = max_trees\n",
    "        self.error = float('inf')\n",
    "        self.lr_decrement = lr_decrement\n",
    "        self.sigma = 0.1\n",
    "    \n",
    "    def predict(self, data):\n",
    "        return np.array([sum([self.alpha * coef * alg.predict([row])[0] for alg, coef in zip(self.trees, self.coefs)]) for row in data])\n",
    " \n",
    "    def bias_l1(self, y, z):\n",
    "        return np.sign(y - z)\n",
    "    \n",
    "    def bias_l2(self, y, z):\n",
    "        return (y - z)\n",
    "    \n",
    "    def mse(self, y_real, prediction):\n",
    "        return (sum((y_real - prediction)**2)) / len(y_real)\n",
    "                   \n",
    "    def fit_val_base(self, X, X_val, y, y_val):\n",
    "        \n",
    "        def conditions(coef, n_trees):\n",
    "            if coef < self.sigma:\n",
    "                return False\n",
    "            if n_trees >= self.max_trees:\n",
    "                return False\n",
    "            return True\n",
    "        \n",
    "        coef = 1\n",
    "        \n",
    "        while conditions(coef, len(self.trees)):\n",
    "            \n",
    "            tree = MyTreeRegressor(max_depth=self.max_depth, min_leaf = self.min_leaf, max_values=self.max_values)\n",
    "                \n",
    "            if len(self.trees) == 0:\n",
    "                tree.fit(X, y)\n",
    "                self.trees.append(tree)\n",
    "                self.coefs.append(coef)\n",
    "            else:\n",
    "                target = self.predict(X)\n",
    "                tree.fit(X, self.loss(y, target))\n",
    "                self.trees.append(tree)\n",
    "                self.coefs.append(coef)\n",
    "                    \n",
    "            _pred = self.predict(X_val)                    \n",
    "            error = self.mse(y_val, _pred)\n",
    "                \n",
    "            if self.error < error:\n",
    "                self.error = error\n",
    "                self.coefs[-1] = self.coefs[-1] * 0.1\n",
    "                coef *= self.lr_decrement\n",
    "            else:\n",
    "                self.error = error\n",
    "                    \n",
    "        #debugging\n",
    "            print(f'mse: {error}, trees: {len(self.trees)}, current coef: {coef}\\nr2_score: {r2_score(y_val, _pred)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def r2_score(y_true, y_pred):\n",
    "    return 1 - (np.sum((y_true - y_pred) ** 2))/np.sum((y_true - y_true.mean()) ** 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>age</th>\n",
       "      <th>years_of_experience</th>\n",
       "      <th>lesson_price</th>\n",
       "      <th>qualification</th>\n",
       "      <th>physics</th>\n",
       "      <th>chemistry</th>\n",
       "      <th>biology</th>\n",
       "      <th>english</th>\n",
       "      <th>geography</th>\n",
       "      <th>history</th>\n",
       "      <th>mean_exam_points</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>20000.000000</td>\n",
       "      <td>20000.000000</td>\n",
       "      <td>20000.000000</td>\n",
       "      <td>20000.000000</td>\n",
       "      <td>20000.00000</td>\n",
       "      <td>20000.000000</td>\n",
       "      <td>20000.000000</td>\n",
       "      <td>20000.000000</td>\n",
       "      <td>20000.000000</td>\n",
       "      <td>20000.000000</td>\n",
       "      <td>20000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>9999.500000</td>\n",
       "      <td>45.925400</td>\n",
       "      <td>1.983400</td>\n",
       "      <td>1698.100000</td>\n",
       "      <td>1.71445</td>\n",
       "      <td>0.378150</td>\n",
       "      <td>0.128200</td>\n",
       "      <td>0.114850</td>\n",
       "      <td>0.054850</td>\n",
       "      <td>0.031750</td>\n",
       "      <td>0.018900</td>\n",
       "      <td>64.340800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>5773.647028</td>\n",
       "      <td>8.000165</td>\n",
       "      <td>1.777718</td>\n",
       "      <td>524.562578</td>\n",
       "      <td>0.79287</td>\n",
       "      <td>0.484937</td>\n",
       "      <td>0.334321</td>\n",
       "      <td>0.318849</td>\n",
       "      <td>0.227693</td>\n",
       "      <td>0.175338</td>\n",
       "      <td>0.136175</td>\n",
       "      <td>13.536823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>200.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>32.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>4999.750000</td>\n",
       "      <td>41.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1300.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>55.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>9999.500000</td>\n",
       "      <td>46.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1500.000000</td>\n",
       "      <td>2.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>63.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>14999.250000</td>\n",
       "      <td>51.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2150.000000</td>\n",
       "      <td>2.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>73.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>19999.000000</td>\n",
       "      <td>68.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>4050.000000</td>\n",
       "      <td>4.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Id           age  years_of_experience  lesson_price  \\\n",
       "count  20000.000000  20000.000000         20000.000000  20000.000000   \n",
       "mean    9999.500000     45.925400             1.983400   1698.100000   \n",
       "std     5773.647028      8.000165             1.777718    524.562578   \n",
       "min        0.000000     23.000000             0.000000    200.000000   \n",
       "25%     4999.750000     41.000000             0.000000   1300.000000   \n",
       "50%     9999.500000     46.000000             2.000000   1500.000000   \n",
       "75%    14999.250000     51.000000             3.000000   2150.000000   \n",
       "max    19999.000000     68.000000            10.000000   4050.000000   \n",
       "\n",
       "       qualification       physics     chemistry       biology       english  \\\n",
       "count    20000.00000  20000.000000  20000.000000  20000.000000  20000.000000   \n",
       "mean         1.71445      0.378150      0.128200      0.114850      0.054850   \n",
       "std          0.79287      0.484937      0.334321      0.318849      0.227693   \n",
       "min          1.00000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%          1.00000      0.000000      0.000000      0.000000      0.000000   \n",
       "50%          2.00000      0.000000      0.000000      0.000000      0.000000   \n",
       "75%          2.00000      1.000000      0.000000      0.000000      0.000000   \n",
       "max          4.00000      1.000000      1.000000      1.000000      1.000000   \n",
       "\n",
       "          geography       history  mean_exam_points  \n",
       "count  20000.000000  20000.000000      10000.000000  \n",
       "mean       0.031750      0.018900         64.340800  \n",
       "std        0.175338      0.136175         13.536823  \n",
       "min        0.000000      0.000000         32.000000  \n",
       "25%        0.000000      0.000000         55.000000  \n",
       "50%        0.000000      0.000000         63.000000  \n",
       "75%        0.000000      0.000000         73.000000  \n",
       "max        1.000000      1.000000        100.000000  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = pd.read_csv('kaggle_data/train.csv')\n",
    "test_df = pd.read_csv('kaggle_data/test.csv')\n",
    "\n",
    "train_ind = train_df.shape[0]\n",
    "df = pd.concat([train_df, test_df], sort=False)\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>age</th>\n",
       "      <th>years_of_experience</th>\n",
       "      <th>lesson_price</th>\n",
       "      <th>qualification</th>\n",
       "      <th>physics</th>\n",
       "      <th>chemistry</th>\n",
       "      <th>biology</th>\n",
       "      <th>english</th>\n",
       "      <th>geography</th>\n",
       "      <th>history</th>\n",
       "      <th>mean_exam_points</th>\n",
       "      <th>qual_mult_years</th>\n",
       "      <th>qual_mult_years_0.5</th>\n",
       "      <th>log_price</th>\n",
       "      <th>price_feature_1</th>\n",
       "      <th>price_feature_2</th>\n",
       "      <th>price_feature_3</th>\n",
       "      <th>age_min_years_of_exp</th>\n",
       "      <th>age_min_years_of_exp_0.5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>20000.000000</td>\n",
       "      <td>20000.000000</td>\n",
       "      <td>20000.000000</td>\n",
       "      <td>20000.000000</td>\n",
       "      <td>20000.00000</td>\n",
       "      <td>20000.000000</td>\n",
       "      <td>20000.000000</td>\n",
       "      <td>20000.000000</td>\n",
       "      <td>20000.000000</td>\n",
       "      <td>20000.000000</td>\n",
       "      <td>20000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>20000.000000</td>\n",
       "      <td>20000.000000</td>\n",
       "      <td>20000.000000</td>\n",
       "      <td>20000.000000</td>\n",
       "      <td>20000.000000</td>\n",
       "      <td>20000.000000</td>\n",
       "      <td>20000.000000</td>\n",
       "      <td>20000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>9999.500000</td>\n",
       "      <td>45.925400</td>\n",
       "      <td>1.983400</td>\n",
       "      <td>1698.100000</td>\n",
       "      <td>1.71445</td>\n",
       "      <td>0.378150</td>\n",
       "      <td>0.128200</td>\n",
       "      <td>0.114850</td>\n",
       "      <td>0.054850</td>\n",
       "      <td>0.031750</td>\n",
       "      <td>0.018900</td>\n",
       "      <td>64.340800</td>\n",
       "      <td>5.391750</td>\n",
       "      <td>2.901318</td>\n",
       "      <td>7.391729</td>\n",
       "      <td>557.502496</td>\n",
       "      <td>1122.578368</td>\n",
       "      <td>826.855188</td>\n",
       "      <td>43.942000</td>\n",
       "      <td>44.775745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>5773.647028</td>\n",
       "      <td>8.000165</td>\n",
       "      <td>1.777718</td>\n",
       "      <td>524.562578</td>\n",
       "      <td>0.79287</td>\n",
       "      <td>0.484937</td>\n",
       "      <td>0.334321</td>\n",
       "      <td>0.318849</td>\n",
       "      <td>0.227693</td>\n",
       "      <td>0.175338</td>\n",
       "      <td>0.136175</td>\n",
       "      <td>13.536823</td>\n",
       "      <td>4.805012</td>\n",
       "      <td>1.849101</td>\n",
       "      <td>0.301641</td>\n",
       "      <td>404.299562</td>\n",
       "      <td>440.276724</td>\n",
       "      <td>555.596633</td>\n",
       "      <td>8.086582</td>\n",
       "      <td>8.013050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>200.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>5.298317</td>\n",
       "      <td>18.181818</td>\n",
       "      <td>75.592895</td>\n",
       "      <td>28.571429</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>20.550510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>4999.750000</td>\n",
       "      <td>41.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1300.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>55.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.732051</td>\n",
       "      <td>7.170120</td>\n",
       "      <td>241.666667</td>\n",
       "      <td>779.422863</td>\n",
       "      <td>400.000000</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>39.267949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>9999.500000</td>\n",
       "      <td>46.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1500.000000</td>\n",
       "      <td>2.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>63.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>7.313220</td>\n",
       "      <td>400.000000</td>\n",
       "      <td>1073.312629</td>\n",
       "      <td>625.000000</td>\n",
       "      <td>44.000000</td>\n",
       "      <td>45.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>14999.250000</td>\n",
       "      <td>51.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2150.000000</td>\n",
       "      <td>2.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>73.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>7.673223</td>\n",
       "      <td>750.000000</td>\n",
       "      <td>1400.000000</td>\n",
       "      <td>1200.000000</td>\n",
       "      <td>49.000000</td>\n",
       "      <td>50.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>19999.000000</td>\n",
       "      <td>68.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>4050.000000</td>\n",
       "      <td>4.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>33.000000</td>\n",
       "      <td>11.313708</td>\n",
       "      <td>8.306472</td>\n",
       "      <td>2200.000000</td>\n",
       "      <td>2700.000000</td>\n",
       "      <td>2700.000000</td>\n",
       "      <td>68.000000</td>\n",
       "      <td>68.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Id           age  years_of_experience  lesson_price  \\\n",
       "count  20000.000000  20000.000000         20000.000000  20000.000000   \n",
       "mean    9999.500000     45.925400             1.983400   1698.100000   \n",
       "std     5773.647028      8.000165             1.777718    524.562578   \n",
       "min        0.000000     23.000000             0.000000    200.000000   \n",
       "25%     4999.750000     41.000000             0.000000   1300.000000   \n",
       "50%     9999.500000     46.000000             2.000000   1500.000000   \n",
       "75%    14999.250000     51.000000             3.000000   2150.000000   \n",
       "max    19999.000000     68.000000            10.000000   4050.000000   \n",
       "\n",
       "       qualification       physics     chemistry       biology       english  \\\n",
       "count    20000.00000  20000.000000  20000.000000  20000.000000  20000.000000   \n",
       "mean         1.71445      0.378150      0.128200      0.114850      0.054850   \n",
       "std          0.79287      0.484937      0.334321      0.318849      0.227693   \n",
       "min          1.00000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%          1.00000      0.000000      0.000000      0.000000      0.000000   \n",
       "50%          2.00000      0.000000      0.000000      0.000000      0.000000   \n",
       "75%          2.00000      1.000000      0.000000      0.000000      0.000000   \n",
       "max          4.00000      1.000000      1.000000      1.000000      1.000000   \n",
       "\n",
       "          geography       history  mean_exam_points  qual_mult_years  \\\n",
       "count  20000.000000  20000.000000      10000.000000     20000.000000   \n",
       "mean       0.031750      0.018900         64.340800         5.391750   \n",
       "std        0.175338      0.136175         13.536823         4.805012   \n",
       "min        0.000000      0.000000         32.000000         1.000000   \n",
       "25%        0.000000      0.000000         55.000000         2.000000   \n",
       "50%        0.000000      0.000000         63.000000         4.000000   \n",
       "75%        0.000000      0.000000         73.000000         6.000000   \n",
       "max        1.000000      1.000000        100.000000        33.000000   \n",
       "\n",
       "       qual_mult_years_0.5     log_price  price_feature_1  price_feature_2  \\\n",
       "count         20000.000000  20000.000000     20000.000000     20000.000000   \n",
       "mean              2.901318      7.391729       557.502496      1122.578368   \n",
       "std               1.849101      0.301641       404.299562       440.276724   \n",
       "min               1.000000      5.298317        18.181818        75.592895   \n",
       "25%               1.732051      7.170120       241.666667       779.422863   \n",
       "50%               2.000000      7.313220       400.000000      1073.312629   \n",
       "75%               4.000000      7.673223       750.000000      1400.000000   \n",
       "max              11.313708      8.306472      2200.000000      2700.000000   \n",
       "\n",
       "       price_feature_3  age_min_years_of_exp  age_min_years_of_exp_0.5  \n",
       "count     20000.000000          20000.000000              20000.000000  \n",
       "mean        826.855188             43.942000                 44.775745  \n",
       "std         555.596633              8.086582                  8.013050  \n",
       "min          28.571429             17.000000                 20.550510  \n",
       "25%         400.000000             38.000000                 39.267949  \n",
       "50%         625.000000             44.000000                 45.000000  \n",
       "75%        1200.000000             49.000000                 50.000000  \n",
       "max        2700.000000             68.000000                 68.000000  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['qual_mult_years'] = df['qualification'] * (df['years_of_experience'] + 1)\n",
    "df['qual_mult_years_0.5'] = df['qualification'] * ((df['years_of_experience'] + 1) ** 0.5)\n",
    "df['log_price'] = np.log(df['lesson_price'])\n",
    "df['price_feature_1'] = df['lesson_price'] / df['qual_mult_years']\n",
    "df['price_feature_2'] = df['lesson_price'] / ((df['years_of_experience'] + 1) ** 0.5)\n",
    "df['price_feature_3'] = df['lesson_price'] / (df['years_of_experience'] + 1)\n",
    "df['age_min_years_of_exp'] = df['age'] - df['years_of_experience']\n",
    "df['age_min_years_of_exp_0.5'] = df['age'] - df['years_of_experience'] ** 0.5\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df[:train_ind]\n",
    "df_test = df[train_ind:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = [col for col in df_train.columns if col not in ['Id', 'mean_exam_points']]\n",
    "target = 'mean_exam_points'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8000, 18)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X, X_val, y, y_val = train_test_split(df_train[columns], df_train[target], test_size=0.2, random_state=35)\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mse: 2784.035530918676, trees: 1, current coef: 1\n",
      "r2_score: -13.906790197324968\n",
      "mse: 1797.2145097328648, trees: 2, current coef: 1\n",
      "r2_score: -8.622973320076738\n",
      "mse: 1164.8830772169647, trees: 3, current coef: 1\n",
      "r2_score: -5.237229174570765\n",
      "mse: 761.2551833781301, trees: 4, current coef: 1\n",
      "r2_score: -3.0760511779457635\n",
      "mse: 501.8769616728644, trees: 5, current coef: 1\n",
      "r2_score: -1.6872410532991964\n",
      "mse: 336.2745008447629, trees: 6, current coef: 1\n",
      "r2_score: -0.8005421903322258\n",
      "mse: 229.95070772015808, trees: 7, current coef: 1\n",
      "r2_score: -0.23124396856374863\n",
      "mse: 161.644399855732, trees: 8, current coef: 1\n",
      "r2_score: 0.13449410811693974\n",
      "mse: 118.05589974956546, trees: 9, current coef: 1\n",
      "r2_score: 0.3678835957447397\n",
      "mse: 90.18589964924658, trees: 10, current coef: 1\n",
      "r2_score: 0.517110227258952\n",
      "mse: 71.92832207565236, trees: 11, current coef: 1\n",
      "r2_score: 0.6148682750203427\n",
      "mse: 60.250201827909684, trees: 12, current coef: 1\n",
      "r2_score: 0.6773973938117208\n",
      "mse: 52.74662738070192, trees: 13, current coef: 1\n",
      "r2_score: 0.7175743990159695\n",
      "mse: 47.92749284120306, trees: 14, current coef: 1\n",
      "r2_score: 0.7433778870516589\n",
      "mse: 44.81026388785817, trees: 15, current coef: 1\n",
      "r2_score: 0.7600687221679779\n",
      "mse: 42.84486940358794, trees: 16, current coef: 1\n",
      "r2_score: 0.7705921953444614\n",
      "mse: 41.54455371818466, trees: 17, current coef: 1\n",
      "r2_score: 0.7775545824610502\n",
      "mse: 40.68178564293993, trees: 18, current coef: 1\n",
      "r2_score: 0.7821741724568643\n",
      "mse: 40.169744530674784, trees: 19, current coef: 1\n",
      "r2_score: 0.7849158362568318\n",
      "mse: 39.79967700920582, trees: 20, current coef: 1\n",
      "r2_score: 0.7868973191941419\n",
      "mse: 39.562981827344615, trees: 21, current coef: 1\n",
      "r2_score: 0.7881646756547687\n",
      "mse: 39.398332293133535, trees: 22, current coef: 1\n",
      "r2_score: 0.7890462721844518\n",
      "mse: 39.29467295023939, trees: 23, current coef: 1\n",
      "r2_score: 0.7896013039214227\n",
      "mse: 39.218374624007886, trees: 24, current coef: 1\n",
      "r2_score: 0.7900098343187214\n",
      "mse: 39.17089165639484, trees: 25, current coef: 1\n",
      "r2_score: 0.7902640762737152\n",
      "mse: 39.12272889385147, trees: 26, current coef: 1\n",
      "r2_score: 0.7905219581105614\n",
      "mse: 39.11370179045724, trees: 27, current coef: 1\n",
      "r2_score: 0.7905702926719893\n",
      "mse: 39.0774176982435, trees: 28, current coef: 1\n",
      "r2_score: 0.7907645715682623\n",
      "mse: 39.08295558396104, trees: 29, current coef: 0.7\n",
      "r2_score: 0.7907349196117366\n",
      "mse: 39.08165802118766, trees: 30, current coef: 0.7\n",
      "r2_score: 0.7907418672587107\n",
      "mse: 39.07493926028583, trees: 31, current coef: 0.7\n",
      "r2_score: 0.7907778420722634\n",
      "mse: 39.07775644137008, trees: 32, current coef: 0.48999999999999994\n",
      "r2_score: 0.7907627578081065\n",
      "mse: 39.07443932142896, trees: 33, current coef: 0.48999999999999994\n",
      "r2_score: 0.790780518935963\n",
      "mse: 39.076031483495875, trees: 34, current coef: 0.3429999999999999\n",
      "r2_score: 0.7907719938917854\n",
      "mse: 39.07563223273688, trees: 35, current coef: 0.3429999999999999\n",
      "r2_score: 0.7907741316329295\n",
      "mse: 39.07629070854001, trees: 36, current coef: 0.24009999999999992\n",
      "r2_score: 0.790770605901832\n",
      "mse: 39.075902897559686, trees: 37, current coef: 0.24009999999999992\n",
      "r2_score: 0.7907726823900294\n",
      "mse: 39.075088010087235, trees: 38, current coef: 0.24009999999999992\n",
      "r2_score: 0.7907770456089794\n",
      "mse: 39.07546105849008, trees: 39, current coef: 0.16806999999999994\n",
      "r2_score: 0.7907750481652639\n",
      "mse: 39.0751432381992, trees: 40, current coef: 0.16806999999999994\n",
      "r2_score: 0.7907767498965614\n",
      "mse: 39.074605804597226, trees: 41, current coef: 0.16806999999999994\n",
      "r2_score: 0.7907796275214553\n",
      "mse: 39.07473387448143, trees: 42, current coef: 0.11764899999999995\n",
      "r2_score: 0.7907789417863516\n",
      "mse: 39.07472746612549, trees: 43, current coef: 0.11764899999999995\n",
      "r2_score: 0.7907789760991383\n",
      "mse: 39.07471733955972, trees: 44, current coef: 0.11764899999999995\n",
      "r2_score: 0.7907790303206416\n",
      "mse: 39.07442593360214, trees: 45, current coef: 0.11764899999999995\n",
      "r2_score: 0.7907805906195047\n",
      "mse: 39.07427785493665, trees: 46, current coef: 0.11764899999999995\n",
      "r2_score: 0.7907813834892695\n",
      "mse: 39.07432377609096, trees: 47, current coef: 0.08235429999999996\n",
      "r2_score: 0.7907811376098596\n"
     ]
    }
   ],
   "source": [
    "model = MyGradienBoost(max_depth = 5, alpha = 0.2, max_trees = 75, lr_decrement = 0.7, min_leaf = 5)\n",
    "model.fit_val_base(X.values, X_val.values, y.values, y_val.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>mean_exam_points</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10000</td>\n",
       "      <td>55.524054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10001</td>\n",
       "      <td>63.917991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10002</td>\n",
       "      <td>47.185339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10003</td>\n",
       "      <td>90.365954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10004</td>\n",
       "      <td>88.974492</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Id  mean_exam_points\n",
       "0  10000         55.524054\n",
       "1  10001         63.917991\n",
       "2  10002         47.185339\n",
       "3  10003         90.365954\n",
       "4  10004         88.974492"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = model.predict(df_test[columns].values)\n",
    "predictions_df = pd.read_csv('kaggle_data/submission_example.csv')\n",
    "predictions_df['mean_exam_points'] = predictions\n",
    "predictions_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_df.to_csv('kaggle_data/predictions_final.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
